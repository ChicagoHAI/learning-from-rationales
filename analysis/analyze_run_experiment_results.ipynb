{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Imports and Setup](#imports)\n",
    "* [File Input](#file_input)\n",
    "* [Experimental Condition Regression](#condition_regression)\n",
    "* [Scatterplots](#scatterplots)\n",
    "* [Line plots](#line_plots)\n",
    "* [File output](#file_output)\n",
    "<!-- * [Second Bullet Header](#second-bullet) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sam/learn_from_explanations_v2/analysis\n",
      "<module 'util' from '../util/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "import os\n",
    "import shutil\n",
    "print(os.getcwd())\n",
    "import time\n",
    "\n",
    "import sys\n",
    "if os.getcwd().split('/')[-1] == 'analysis':\n",
    "    sys.path.insert(0,'..')\n",
    "else:\n",
    "    sys.path.insert(0,'../../..')\n",
    "\n",
    "\n",
    "import util\n",
    "print(util)\n",
    "\n",
    "from util.misc_util import subdir_paths\n",
    "from util.config_util import parse_combo_name\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "from traceback import print_exc\n",
    "from typing import List, Union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Union, Dict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__init__.py', 'analyze_cross_evaluation_results.ipynb', 'analyze_new_reddit_results.ipynb', 'val_selective_supervision_paper_plots.ipynb', 'analyze_single_prediction_file.ipynb', 'columns.txt', 'analyze_single_prediction_file-Copy1.ipynb', 'analyze_delegation_rules.ipynb', 'describe_dataset.ipynb', '.ipynb_checkpoints', 'selective_supervision_paper_plots-Copy1.ipynb', 'analyze_run_experiment_results.ipynb', 'plot_fidelity_curves.ipynb', 'analyze_reddit_wiki_results.ipynb', 'selective_supervision_paper_plots.ipynb', 'gumbel_softmax.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardcoded stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result directory: ../output/run_experiment/refiner_debug_3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_name = 'test'\n",
    "notebook_name = 'analyze_run_experiment_results.ipynb' #Jupyter Notebooks can't easily figure out their own name--why???\n",
    "\n",
    "# result_directory = '../output/run_experiment_aws/full_experiment_5'\n",
    "\n",
    "# result_directory = '../output/run_experiment/debug_squared_cohesiveness'\n",
    "# result_directory = '../output/run_experiment/wikiattack_debugging'\n",
    "# result_directory = '../output/run_experiment_aws/data2/full_experiment'\n",
    "# result_directory = '../output/run_experiment/calibrated_models'\n",
    "# result_directory = '../output/run_experiment_aws/data2/calibrated_models_2'\n",
    "# result_directory = '../output/run_experiment/calibration_debug_4'\n",
    "# result_directory = '../output/run_experiment_aws/data2/calibrated_models_3'\n",
    "# result_directory_2 = '../output/run_experiment/calibrated_models_4'\n",
    "# result_directory = '../output/run_experiment_aws/data2/full_experiment_best_models'\n",
    "\n",
    "# result_directory = '../output/run_experiment_bingo/selective_masking_paper_2'\n",
    "\n",
    "result_directory = '../output/run_experiment/refiner_debug_3'\n",
    "\n",
    "evaluation_filter = lambda p: 'n' in p and p['n'] == 'sigmoid' \n",
    "# paramset_filter = None \n",
    "\n",
    "result_directories = [result_directory]\n",
    "\n",
    "\n",
    "#This notebook either gets run out of the analysis directory, or out of the individual result directory\n",
    "if os.getcwd().split('/')[-1] != 'analysis': \n",
    "    result_directory = '.'\n",
    "\n",
    "print(f'Result directory: {result_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " beeradvocate_aroma_rationales_23k ../output/run_experiment/refiner_debug_3/beeradvocate_aroma_rationales_23k\n",
      "\t bert_classification\n",
      "\t\t debug_trainer\n",
      "\t\t\t cwm=human_ims=multiply_mask\n",
      "\t\t\t default\n",
      "\t bert_rationale_reinforce_debug\n",
      "\t\t debug_trainer\n",
      "\t\t\t bs=bernoulli_clwm=0_ewhim=False_hrlw=0.0_ms=removal_plw=1.0_so=True_slw=0.2_twhim=False_trlw=0.0_p=True\n",
      "\t\t\t bs=bernoulli_clwm=0_ewhim=False_hrlw=0.0_ms=removal_plw=1.0_so=True_slw=0.3_twhim=False_trlw=0.0_p=True\n",
      "\t\t\t bs=bernoulli_clwm=0_ewhim=False_hrlw=0.0_ms=removal_plw=1.0_so=True_slw=0.5_twhim=False_trlw=0.0_p=True\n",
      "\t lstm_classification\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t default\n",
      "\t\t\t lr=0.0001\n",
      "\t\t\t lr=0.001\n",
      "\t restructured_bert_rationale\n",
      "\t\t debug_trainer\n",
      "\t\t\t bs=bert_attention_ewhim=False_hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t bs=sigmoid_ewhim=False_hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=longs_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=longs_plw=1.0_slw=0.3_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=longs_plw=1.0_slw=0.4_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=repeat_1_plw=1.0_slw=0.3_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.3_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.7_twhim=False_p=True\n",
      "\t restructured_lstm_rationale\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.0001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=gumbel_softmax_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=0.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=1.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_mask_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.01\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_clwm=2.0_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t bs=sigmoid_hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t bs=sigmoid_hrlw=0.0_lr=0.001_plw=1.0_slw=0.05\n",
      "\t\t\t hrlw=0.0_lr=0.0001_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_lr=0.0001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t hrlw=0.0_lr=0.0001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.05\n",
      "\t\t\t hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\n",
      " beeradvocate_taste_rationales_23k ../output/run_experiment/refiner_debug_3/beeradvocate_taste_rationales_23k\n",
      "\t bert_classification\n",
      "\t\t debug_trainer\n",
      "\t\t\t default\n",
      "\n",
      " multirc ../output/run_experiment/refiner_debug_3/multirc\n",
      "\t bert_classification\n",
      "\t\t debug_trainer\n",
      "\t\t\t agb=1_cwm=human_ims=multiply_mask\n",
      "\t\t\t cwm=human_ims=multiply_mask\n",
      "\t\t\t default\n",
      "\t\t\t ewhim=True_twhim=True\n",
      "\t bert_rationale_prediction\n",
      "\t\t debug_trainer\n",
      "\t\t\t default\n",
      "\t\t\t ewhim=True_ims=0_1_embeddings_twhim=True\n",
      "\t\t\t ewhim=True_ims=embeddings_twhim=True\n",
      "\t\t\t ewhim=True_ims=token_type_ids_twhim=True\n",
      "\t restructured_bert_rationale\n",
      "\t\t debug_trainer\n",
      "\t\t\t agb=10_ewhim=False_hrlw=0.0_lr=1e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t agb=10_ewhim=False_hrlw=0.0_lr=2e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t agb=1_ewhim=False_hrlw=0.0_lr=1e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t agb=1_ewhim=False_hrlw=0.0_lr=2e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t agb=20_ewhim=False_hrlw=0.0_lr=1e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t agb=20_ewhim=False_hrlw=0.0_lr=2e-05_n=longs_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_mask_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_zero_n=sigmoid_plw=1.0_twhim=True_p=True\n",
      "\t\t\t\tSuccess!\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ms=multiply_mask_plw=1.0_twhim=True_p=True\n",
      "\t\t\t ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ms=multiply_zero_plw=1.0_twhim=True_p=True\n",
      "\t\t\t aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_mask_plw=1.0_twhim=True_p=True\n",
      "\t\t\t aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ms=multiply_mask_plw=1.0_twhim=True_p=True\n",
      "\t\t\t aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ms=multiply_zero_plw=1.0_twhim=True_p=True\n",
      "\t\t\t bs=sigmoid_ewhim=True_hrlw=0.0_plw=1.0_twhim=True_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=alt_pretrain_plw=1.0_slw=0.05_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=alt_pretrain_plw=1.0_slw=0.15_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=alt_pretrain_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_n=long_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.1_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_n=long_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_n=no_gen_pre_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_n=no_gen_pre_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_n=tinker_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=0_1_embeddings_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=embeddings_n=no_gen_pre_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=embeddings_n=no_gen_pre_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=embeddings_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=embeddings_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=token_type_ids_n=no_gen_pre_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=token_type_ids_n=no_gen_pre_plw=1.0_slw=0.2_p=True\n",
      "\t\t\t hrlw=0.0_ims=token_type_ids_plw=1.0_slw=0.0_p=True\n",
      "\t\t\t hrlw=0.0_ims=token_type_ids_plw=1.0_slw=0.2_p=True\n",
      "\t restructured_lstm_rationale\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t debug_trainer\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\n",
      " two_class_good_bad_neutral ../output/run_experiment/refiner_debug_3/two_class_good_bad_neutral\n",
      "\t bert_classification\n",
      "\t\t debug_trainer\n",
      "\t\t\t default\n",
      "\t restructured_bert_rationale\n",
      "\t\t debug_trainer\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.2_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.3_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.4_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.5_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.6_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.7_twhim=False_p=True\n",
      "\t\t\t ewhim=False_hrlw=0.0_plw=1.0_slw=0.8_twhim=False_p=True\n",
      "\t restructured_lstm_rationale\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.0001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_slw=0.1\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.05\n",
      "\t\t\t bs=bernoulli_hrlw=0.0_lr=0.001_ls=reinforce_ms=removal_plw=1.0_so=True_slw=0.1\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\n",
      " wiki_attack_rationales ../output/run_experiment/refiner_debug_3/wiki_attack_rationales\n",
      "\t lstm_classification\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t lr=0.0001\n",
      "\t\t\t lr=0.001\n",
      "\t restructured_lstm_rationale\n",
      "\t\t debug_lstm_trainer\n",
      "\t\t\t hrlw=0.0_lr=0.0001_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_lr=0.0001_ms=multiply_zero_plw=1.0_slw=0.1\n",
      "\t\t\t hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0\n",
      "\t\t\t hrlw=0.0_lr=0.001_ms=multiply_zero_plw=1.0_slw=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 evaluations successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "prefix=set_name\n",
    "hyperparams = set()\n",
    "evaluations = []\n",
    "true_rationale_stats = {}\n",
    "\n",
    "for result_directory in result_directories:\n",
    "    for dataset, dataset_dir in subdir_paths(result_directory):\n",
    "#         read_predictions = False\n",
    "        if dataset.startswith('.'): continue #skip .ipynb_checkpoints\n",
    "        print('\\n',dataset, dataset_dir)\n",
    "        for model, model_dir in subdir_paths(dataset_dir):\n",
    "            print('\\t',model)\n",
    "            for trainer, trainer_dir in subdir_paths(model_dir):\n",
    "                print('\\t\\t',trainer)\n",
    "    #             for paramset, paramset_dir in subdir_paths(model_dir):\n",
    "                for paramset, paramset_dir in subdir_paths(trainer_dir):\n",
    "   \n",
    "\n",
    "                    combo = parse_combo_name(paramset)\n",
    "                    print('\\t\\t\\t',paramset)\n",
    "                    evaluation = {'dataset':dataset,\n",
    "                                  'model':model,\n",
    "                                  'trainer':trainer,\n",
    "                                  'paramset':paramset,\n",
    "                                 'directory':os.path.abspath(paramset_dir)}\n",
    "                    evaluation.update(combo)\n",
    "                \n",
    "                    if evaluation_filter is not None and not evaluation_filter(evaluation):\n",
    "                        print('\\t\\t\\t\\tFiltered out!')\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        epoch_eval = pd.read_json(os.path.join(paramset_dir, f'{prefix}_output',f'{prefix}_epoch_eval.json'), orient='records', lines=True)\n",
    "                        evaluation.update(epoch_eval.iloc[-1].to_dict()) #Just grab the evaluation for the final epoch, for now\n",
    "                        evaluations.append(evaluation)\n",
    "                        hyperparams.update(combo.keys())\n",
    "                        print('\\t\\t\\t\\tSuccess!')\n",
    "                    except Exception as ex:\n",
    "                        print('\\t\\t\\t\\tException:',ex)\n",
    "                        print('\\t\\t\\t\\tPath:',os.path.abspath(paramset_dir))\n",
    "\n",
    "#                     if not read_predictions:\n",
    "#                         try:\n",
    "#                             predictions_path = os.path.join(paramset_dir, f'{prefix}_output',f'epoch_-1_predictions.json')\n",
    "#                             print(f'\\tReading {dataset} predictions at {predictions_path}')\n",
    "#                             prediction_df = pd.read_json(predictions_path, lines=True, orient='records')\n",
    "\n",
    "#                             true_rationale_stats[dataset] = {'rationale_mean':prediction_df.apply(lambda s:np.array(s['rationale'])[np.nonzero(s['rationale_weight'])].mean(),axis=1).mean()}\n",
    "\n",
    "#                             read_predictions = True\n",
    "#                         except Exception as ex:\n",
    "#                             print('\\t\\t\\tException:',ex)\n",
    "#                             print('\\t\\t\\tPath:',os.path.abspath(paramset_dir))\n",
    "                \n",
    "evaluation_df = pd.DataFrame(evaluations)\n",
    "# for col in evaluation_df.columns:\n",
    "#     evaluation_df[col] = evaluation_df[col].fillna(0) if pd.api.types.is_numeric_dtype(evaluation_df[col]) else evaluation_df[col].fillna('none')\n",
    "\n",
    "evaluation_df['index'] = evaluation_df.index\n",
    "\n",
    "evaluation_df.rename(columns=lambda column:column.replace(prefix+'_', ''), inplace=True)\n",
    "\n",
    "hyperparams = list(hyperparams)\n",
    "\n",
    "print(f'{len(evaluations)} evaluations successfully loaded.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "model\n",
      "trainer\n",
      "paramset\n",
      "directory\n",
      "ahrtpr\n",
      "aima\n",
      "bs\n",
      "ewhim\n",
      "hrlw\n",
      "ims\n",
      "ms\n",
      "n\n",
      "plw\n",
      "twhim\n",
      "p\n",
      "type\n",
      "epoch\n",
      "datetime\n",
      "step\n",
      "prediction_loss\n",
      "last_class_mse_loss\n",
      "sparsity_loss\n",
      "cohesiveness_loss\n",
      "binarization_loss\n",
      "collapse_loss\n",
      "human_rationale_loss\n",
      "loss\n",
      "test/predicted_rationale/mean\n",
      "test/predicted_rationale/sufficiency_prediction_loss\n",
      "test/predicted_rationale/sufficiency_last_class_mse_loss\n",
      "test/predicted_rationale/sufficiency_sparsity_loss\n",
      "test/predicted_rationale/sufficiency_cohesiveness_loss\n",
      "test/predicted_rationale/sufficiency_binarization_loss\n",
      "test/predicted_rationale/sufficiency_collapse_loss\n",
      "test/predicted_rationale/sufficiency_human_rationale_loss\n",
      "test/predicted_rationale/sufficiency_loss\n",
      "test/predicted_rationale/sufficiency\n",
      "test/human_rationale/mean\n",
      "test/human_rationale/sufficiency_prediction_loss\n",
      "test/human_rationale/sufficiency_last_class_mse_loss\n",
      "test/human_rationale/sufficiency_sparsity_loss\n",
      "test/human_rationale/sufficiency_cohesiveness_loss\n",
      "test/human_rationale/sufficiency_binarization_loss\n",
      "test/human_rationale/sufficiency_collapse_loss\n",
      "test/human_rationale/sufficiency_human_rationale_loss\n",
      "test/human_rationale/sufficiency_loss\n",
      "test/human_rationale/sufficiency\n",
      "test/rationale_full_info/mean\n",
      "test/rationale_full_info/sufficiency_prediction_loss\n",
      "test/rationale_full_info/sufficiency_last_class_mse_loss\n",
      "test/rationale_full_info/sufficiency_sparsity_loss\n",
      "test/rationale_full_info/sufficiency_cohesiveness_loss\n",
      "test/rationale_full_info/sufficiency_binarization_loss\n",
      "test/rationale_full_info/sufficiency_collapse_loss\n",
      "test/rationale_full_info/sufficiency_human_rationale_loss\n",
      "test/rationale_full_info/sufficiency_loss\n",
      "test/rationale_full_info/sufficiency\n",
      "test/accuracy\n",
      "test/f1\n",
      "test/precision\n",
      "test/recall\n",
      "test/py_sparsity_deviation\n",
      "test/predicted_rationale/accuracy\n",
      "test/predicted_rationale/f1\n",
      "test/predicted_rationale/precision\n",
      "test/predicted_rationale/recall\n",
      "test/predicted_rationale/sufficiency_accuracy\n",
      "test/predicted_rationale/sufficiency_f1\n",
      "test/predicted_rationale/sufficiency_precision\n",
      "test/predicted_rationale/sufficiency_recall\n",
      "test/predicted_rationale/sufficiency_py_sparsity_deviation\n",
      "test/human_rationale/accuracy\n",
      "test/human_rationale/f1\n",
      "test/human_rationale/precision\n",
      "test/human_rationale/recall\n",
      "test/human_rationale/sufficiency_accuracy\n",
      "test/human_rationale/sufficiency_f1\n",
      "test/human_rationale/sufficiency_precision\n",
      "test/human_rationale/sufficiency_recall\n",
      "test/human_rationale/sufficiency_py_sparsity_deviation\n",
      "test/rationale_full_info/accuracy\n",
      "test/rationale_full_info/f1\n",
      "test/rationale_full_info/precision\n",
      "test/rationale_full_info/recall\n",
      "test/rationale_full_info/sufficiency_accuracy\n",
      "test/rationale_full_info/sufficiency_f1\n",
      "test/rationale_full_info/sufficiency_precision\n",
      "test/rationale_full_info/sufficiency_recall\n",
      "test/rationale_full_info/sufficiency_py_sparsity_deviation\n",
      "index\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(evaluation_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(evaluation_df[hyperparams+[f'{set_name}/accuracy',\n",
    "#                                    f'{set_name}/human_rationale/sufficiency_accuracy',\n",
    "#                                    f'{set_name}/predicted_rationale/f1'\n",
    "#                                   ]].sort_values(f'{set_name}/human_rationale/sufficiency_accuracy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs',\n",
       " 'ahrtpr',\n",
       " 'plw',\n",
       " 'ms',\n",
       " 'p',\n",
       " 'aima',\n",
       " 'hrlw',\n",
       " 'ims',\n",
       " 'twhim',\n",
       " 'n',\n",
       " 'ewhim']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_alpha_df = eval_list_to_p_alpha_df(evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(p_alpha_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(p_alpha_df['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(p_alpha_df['base_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatterplot(data_df:pd.DataFrame=None, \n",
    "                     x:str=None, \n",
    "                     y:str=None, \n",
    "                     hue:str=None, \n",
    "                     size:str=None, \n",
    "                     title:str=None, \n",
    "                     title_prefix:str=None,\n",
    "                     style:str=None, \n",
    "                     xlim:List[str]=None,\n",
    "                     ylim:List[str]=None,\n",
    "                     labels:Union[str,List[str]]=None,\n",
    "                    jitter:float=None,\n",
    "                    horizontal_line_at=None,\n",
    "                    show=True):\n",
    "    try:\n",
    "        print('-----------------------vvvvvvvvvv--------------------------')\n",
    "        # Look at impact of rationale loss weight\n",
    "        plt.figure(figsize=(14,8))\n",
    "\n",
    "\n",
    "        if jitter:\n",
    "            data_df[f'{x}_jitter'] = data_df[x] + np.random.rand(*data_df[x].shape)*jitter-jitter/2\n",
    "            data_df[f'{y}_jitter']= data_df[y] + np.random.rand(*data_df[y].shape)*jitter-jitter/2\n",
    "#             if xlim is not None:\n",
    "#                 data_df[f'{x}_jitter'] = np.clip(data_df[f'{x}_jitter'], *xlim)\n",
    "#             if ylim is not None:\n",
    "#                 data_df[f'{y}_jitter'] = np.clip(data_df[f'{y}_jitter'], *ylim)\n",
    "                \n",
    "            x = f'{x}_jitter'\n",
    "            y= f'{y}_jitter'\n",
    "        \n",
    "        if hue is not None:\n",
    "            num_hues = len(data_df[hue].unique()) if hue is not None else 1\n",
    "            if pd.api.types.is_numeric_dtype(evaluation_df[hue].dtype):\n",
    "                print('Continous palette')\n",
    "                palette =sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "            else:\n",
    "                print('Discrete palette')\n",
    "                palette = sns.color_palette(\"bright\", num_hues)\n",
    "        else:\n",
    "            palette = None\n",
    "\n",
    "        \n",
    "        \n",
    "        bar = sns.scatterplot(x=x, \n",
    "                              y=y,\n",
    "                              hue=hue, \n",
    "                              s=100,\n",
    "        #                 units=\"model_type\",\n",
    "                              size=size,\n",
    "                              data=data_df, \n",
    "                              palette=palette,\n",
    "                              style=style\n",
    "        #                    style_order=style_order,\n",
    "        #                        markers=True,\n",
    "                     );\n",
    "\n",
    "\n",
    "        # bar.set(xscale=\"log\")\n",
    "        #     plt.title(f'{threshold_metric} by threshold value')\n",
    "        # plt.legend(bbox_to_anchor=(1, 1), loc='upper right', ncol=1, frameon=False)\n",
    "\n",
    "        if title is None:\n",
    "            title = f'{y.capitalize()} by {x}'\n",
    "            if jitter:\n",
    "                title = title.replace('_jitter','') + f' with {jitter} jitter'\n",
    "            if title_prefix is not None:\n",
    "                title = title_prefix + title\n",
    "            if labels is not None:\n",
    "                title = title + f' (labeled for {labels})'\n",
    "        plt.title(title)\n",
    "        # plt.xlabel(\"% top tokens\")\n",
    "        # plt.ylabel(metric_to_label[threshold_metric])\n",
    "        if xlim is not None: \n",
    "            plt.xlim(xlim)\n",
    "        if ylim is not None: \n",
    "            plt.ylim(ylim)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        \n",
    "        if labels is not None:\n",
    "            print('Label: ',labels)\n",
    "            if not type(labels) == list:\n",
    "                labels = [labels]\n",
    "            for i, row in data_df.iterrows():\n",
    "                texts = []\n",
    "                for label in labels:\n",
    "                    if data_df[label].dtype == float:\n",
    "                        texts.append(f'{row[label]:.2f}')\n",
    "                    else:\n",
    "                        texts.append(f'{row[label]}')\n",
    "                \n",
    "                bar.text(row[x], row[y], ','.join(texts))\n",
    "            \n",
    "        \n",
    "#         if horizontal_line_at is not None:\n",
    "        if type(horizontal_line_at) != list:\n",
    "            horizontal_line_at = [horizontal_line_at]\n",
    "        for line in horizontal_line_at:\n",
    "            if line is not None:\n",
    "                plt.axhline(line)\n",
    "        plt.tight_layout()\n",
    "        if show:\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "        print('-------------------------^^^^^^^^^-------------------------')\n",
    "        return plt\n",
    "#         display(data_df[['combo_name',x,y]])\n",
    "        \n",
    "    except:\n",
    "        print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale model scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trainer</th>\n",
       "      <th>paramset</th>\n",
       "      <th>directory</th>\n",
       "      <th>ahrtpr</th>\n",
       "      <th>aima</th>\n",
       "      <th>bs</th>\n",
       "      <th>ewhim</th>\n",
       "      <th>hrlw</th>\n",
       "      <th>ims</th>\n",
       "      <th>ms</th>\n",
       "      <th>n</th>\n",
       "      <th>plw</th>\n",
       "      <th>twhim</th>\n",
       "      <th>p</th>\n",
       "      <th>type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>datetime</th>\n",
       "      <th>step</th>\n",
       "      <th>prediction_loss</th>\n",
       "      <th>last_class_mse_loss</th>\n",
       "      <th>sparsity_loss</th>\n",
       "      <th>cohesiveness_loss</th>\n",
       "      <th>binarization_loss</th>\n",
       "      <th>collapse_loss</th>\n",
       "      <th>human_rationale_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>test/predicted_rationale/mean</th>\n",
       "      <th>test/predicted_rationale/sufficiency_prediction_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_sparsity_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_binarization_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_collapse_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency</th>\n",
       "      <th>test/human_rationale/mean</th>\n",
       "      <th>test/human_rationale/sufficiency_prediction_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_sparsity_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_binarization_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_collapse_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_loss</th>\n",
       "      <th>test/human_rationale/sufficiency</th>\n",
       "      <th>test/rationale_full_info/mean</th>\n",
       "      <th>test/rationale_full_info/sufficiency_prediction_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_sparsity_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_binarization_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_collapse_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency</th>\n",
       "      <th>test/accuracy</th>\n",
       "      <th>test/f1</th>\n",
       "      <th>test/precision</th>\n",
       "      <th>test/recall</th>\n",
       "      <th>test/py_sparsity_deviation</th>\n",
       "      <th>test/predicted_rationale/accuracy</th>\n",
       "      <th>test/predicted_rationale/f1</th>\n",
       "      <th>test/predicted_rationale/precision</th>\n",
       "      <th>test/predicted_rationale/recall</th>\n",
       "      <th>test/predicted_rationale/sufficiency_accuracy</th>\n",
       "      <th>test/predicted_rationale/sufficiency_f1</th>\n",
       "      <th>test/predicted_rationale/sufficiency_precision</th>\n",
       "      <th>test/predicted_rationale/sufficiency_recall</th>\n",
       "      <th>test/predicted_rationale/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>test/human_rationale/accuracy</th>\n",
       "      <th>test/human_rationale/f1</th>\n",
       "      <th>test/human_rationale/precision</th>\n",
       "      <th>test/human_rationale/recall</th>\n",
       "      <th>test/human_rationale/sufficiency_accuracy</th>\n",
       "      <th>test/human_rationale/sufficiency_f1</th>\n",
       "      <th>test/human_rationale/sufficiency_precision</th>\n",
       "      <th>test/human_rationale/sufficiency_recall</th>\n",
       "      <th>test/human_rationale/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>test/rationale_full_info/accuracy</th>\n",
       "      <th>test/rationale_full_info/f1</th>\n",
       "      <th>test/rationale_full_info/precision</th>\n",
       "      <th>test/rationale_full_info/recall</th>\n",
       "      <th>test/rationale_full_info/sufficiency_accuracy</th>\n",
       "      <th>test/rationale_full_info/sufficiency_f1</th>\n",
       "      <th>test/rationale_full_info/sufficiency_precision</th>\n",
       "      <th>test/rationale_full_info/sufficiency_recall</th>\n",
       "      <th>test/rationale_full_info/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_m...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_1_embeddings</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-07 17:52:26.582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3.558e-03</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3.558e-03</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3.558e-03</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3.558e-03</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.387</td>\n",
       "      <td>2.829e-05</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.387</td>\n",
       "      <td>2.829e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.387</td>\n",
       "      <td>2.829e-05</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.387</td>\n",
       "      <td>2.829e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_z...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_1_embeddings</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 00:37:21.241</td>\n",
       "      <td>841</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4.470e-03</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4.470e-03</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4.470e-03</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4.470e-03</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.221</td>\n",
       "      <td>4.685e-03</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.221</td>\n",
       "      <td>4.685e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.221</td>\n",
       "      <td>4.685e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.221</td>\n",
       "      <td>4.685e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-07 22:07:48.459</td>\n",
       "      <td>442</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.520e-03</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.520e-03</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.520e-03</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.520e-03</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.311</td>\n",
       "      <td>2.742e-03</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.311</td>\n",
       "      <td>2.742e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.311</td>\n",
       "      <td>2.742e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.311</td>\n",
       "      <td>2.742e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 02:16:12.731</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.999</td>\n",
       "      <td>3.498e-06</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.999</td>\n",
       "      <td>3.498e-06</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.999</td>\n",
       "      <td>3.498e-06</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.999</td>\n",
       "      <td>3.498e-06</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_m...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>token_type_ids</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-07 23:23:05.591</td>\n",
       "      <td>961</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.624e-02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.624e-02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.624e-02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.624e-02</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.356</td>\n",
       "      <td>6.575e-03</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.356</td>\n",
       "      <td>6.575e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.356</td>\n",
       "      <td>6.575e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.356</td>\n",
       "      <td>6.575e-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_z...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>False</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>token_type_ids</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 03:38:20.215</td>\n",
       "      <td>961</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4.593e-04</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.209</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4.593e-04</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.209</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4.593e-04</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.209</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4.593e-04</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.209</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3.792e-05</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3.792e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3.792e-05</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3.792e-05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_ma...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_1_embeddings</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-07 18:24:40.562</td>\n",
       "      <td>262</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.742</td>\n",
       "      <td>2.837e-02</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.742</td>\n",
       "      <td>2.837e-02</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.742</td>\n",
       "      <td>2.837e-02</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.742</td>\n",
       "      <td>2.837e-02</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.614e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.614e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.614e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.614e-03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_ze...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_1_embeddings</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 01:28:53.748</td>\n",
       "      <td>1322</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.671</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.671</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.671</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.671</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.444e-02</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.444e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.444e-02</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.444e-02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_n...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-07 22:43:43.333</td>\n",
       "      <td>841</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.644</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.644</td>\n",
       "      <td>0.595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.644</td>\n",
       "      <td>0.595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.643</td>\n",
       "      <td>5.644</td>\n",
       "      <td>0.595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.459e-02</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.459e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.459e-02</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.459e-02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_n...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 02:58:56.139</td>\n",
       "      <td>1081</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.319e-03</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.319e-03</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.319e-03</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.319e-03</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.346</td>\n",
       "      <td>8.267e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.346</td>\n",
       "      <td>8.267e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.346</td>\n",
       "      <td>8.267e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.346</td>\n",
       "      <td>8.267e-03</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_ma...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>token_type_ids</td>\n",
       "      <td>multiply_mask</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 00:02:28.102</td>\n",
       "      <td>961</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.638</td>\n",
       "      <td>9.318e-02</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.638</td>\n",
       "      <td>9.318e-02</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.638</td>\n",
       "      <td>9.318e-02</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.638</td>\n",
       "      <td>9.318e-02</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2.604e-03</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2.604e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2.604e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.468</td>\n",
       "      <td>2.604e-03</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multirc</td>\n",
       "      <td>restructured_bert_rationale</td>\n",
       "      <td>debug_trainer</td>\n",
       "      <td>ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_ze...</td>\n",
       "      <td>/data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...</td>\n",
       "      <td>True</td>\n",
       "      <td>generator_only</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>token_type_ids</td>\n",
       "      <td>multiply_zero</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-08-08 04:29:28.423</td>\n",
       "      <td>1322</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.465</td>\n",
       "      <td>3.092e-01</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1.887</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.465</td>\n",
       "      <td>3.092e-01</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1.887</td>\n",
       "      <td>0.521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.465</td>\n",
       "      <td>3.092e-01</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1.887</td>\n",
       "      <td>0.521</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.465</td>\n",
       "      <td>3.092e-01</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1.887</td>\n",
       "      <td>0.521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.691</td>\n",
       "      <td>7.896e-03</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.388</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.691</td>\n",
       "      <td>7.896e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.691</td>\n",
       "      <td>7.896e-03</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.691</td>\n",
       "      <td>7.896e-03</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                        model        trainer                                                                                             paramset                                                                                            directory  ahrtpr            aima       bs  ewhim  hrlw             ims             ms        n  plw  twhim     p  type  epoch                datetime  step  prediction_loss  last_class_mse_loss  sparsity_loss  cohesiveness_loss  binarization_loss  collapse_loss  human_rationale_loss   loss  test/predicted_rationale/mean  test/predicted_rationale/sufficiency_prediction_loss  test/predicted_rationale/sufficiency_last_class_mse_loss  test/predicted_rationale/sufficiency_sparsity_loss  test/predicted_rationale/sufficiency_cohesiveness_loss  test/predicted_rationale/sufficiency_binarization_loss  test/predicted_rationale/sufficiency_collapse_loss  test/predicted_rationale/sufficiency_human_rationale_loss  test/predicted_rationale/sufficiency_loss  test/predicted_rationale/sufficiency  test/human_rationale/mean  test/human_rationale/sufficiency_prediction_loss  test/human_rationale/sufficiency_last_class_mse_loss  test/human_rationale/sufficiency_sparsity_loss  test/human_rationale/sufficiency_cohesiveness_loss  test/human_rationale/sufficiency_binarization_loss  test/human_rationale/sufficiency_collapse_loss  test/human_rationale/sufficiency_human_rationale_loss  test/human_rationale/sufficiency_loss  test/human_rationale/sufficiency  test/rationale_full_info/mean  test/rationale_full_info/sufficiency_prediction_loss  test/rationale_full_info/sufficiency_last_class_mse_loss  test/rationale_full_info/sufficiency_sparsity_loss  test/rationale_full_info/sufficiency_cohesiveness_loss  test/rationale_full_info/sufficiency_binarization_loss  test/rationale_full_info/sufficiency_collapse_loss  test/rationale_full_info/sufficiency_human_rationale_loss  test/rationale_full_info/sufficiency_loss  test/rationale_full_info/sufficiency  test/accuracy  test/f1  test/precision  test/recall  test/py_sparsity_deviation  test/predicted_rationale/accuracy  test/predicted_rationale/f1  test/predicted_rationale/precision  test/predicted_rationale/recall  test/predicted_rationale/sufficiency_accuracy  test/predicted_rationale/sufficiency_f1  test/predicted_rationale/sufficiency_precision  test/predicted_rationale/sufficiency_recall  test/predicted_rationale/sufficiency_py_sparsity_deviation  test/human_rationale/accuracy  test/human_rationale/f1  test/human_rationale/precision  test/human_rationale/recall  test/human_rationale/sufficiency_accuracy  test/human_rationale/sufficiency_f1  test/human_rationale/sufficiency_precision  test/human_rationale/sufficiency_recall  test/human_rationale/sufficiency_py_sparsity_deviation  test/rationale_full_info/accuracy  test/rationale_full_info/f1  test/rationale_full_info/precision  test/rationale_full_info/recall  test/rationale_full_info/sufficiency_accuracy  test/rationale_full_info/sufficiency_f1  test/rationale_full_info/sufficiency_precision  test/rationale_full_info/sufficiency_recall  test/rationale_full_info/sufficiency_py_sparsity_deviation  index\n",
       "0   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_m...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0  0_1_embeddings  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-07 17:52:26.582     0            0.639                0.224          0.007          3.558e-03              0.014          0.985                 0.883  0.639                          0.000                                                 0.639                                                     0.224                                               0.007                                               3.558e-03                                                   0.014                                               0.985                                                      0.883                                      0.639                                     1                      0.176                                             0.639                                                 0.224                                           0.007                                           3.558e-03                                               0.014                                           0.985                                                  0.883                                  0.639                                 1                              1                                                 0.639                                                     0.224                                               0.007                                               3.558e-03                                                   0.014                                               0.985                                                      0.883                                      0.639                                     1          0.646    0.483           0.643        0.387                   2.829e-05                              0.827                        0.000                               0.000                            0.000                                          0.646                                    0.483                                           0.643                                        0.387                                                   2.829e-05                              1                        1                               1                            1                                      0.646                                0.483                                       0.643                                    0.387                                               2.829e-05                              0.173                        0.294                               0.173                                1                                          0.646                                    0.483                                           0.643                                        0.387                                                   2.829e-05      0\n",
       "1   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_z...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0  0_1_embeddings  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 00:37:21.241   841            0.658                0.233          0.023          4.470e-03              0.043          0.954                 0.688  0.658                          0.000                                                 0.658                                                     0.233                                               0.023                                               4.470e-03                                                   0.043                                               0.954                                                      0.688                                      0.658                                     1                      0.176                                             0.658                                                 0.233                                           0.023                                           4.470e-03                                               0.043                                           0.954                                                  0.688                                  0.658                                 1                              1                                                 0.658                                                     0.233                                               0.023                                               4.470e-03                                                   0.043                                               0.954                                                      0.688                                      0.658                                     1          0.629    0.338           0.717        0.221                   4.685e-03                              0.827                        0.000                               0.000                            0.000                                          0.629                                    0.338                                           0.717                                        0.221                                                   4.685e-03                              1                        1                               1                            1                                      0.629                                0.338                                       0.717                                    0.221                                               4.685e-03                              0.173                        0.294                               0.173                                1                                          0.629                                    0.338                                           0.717                                        0.221                                                   4.685e-03      1\n",
       "2   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0      embeddings  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-07 22:07:48.459   442            0.633                0.222          0.021          3.520e-03              0.038          0.959                 0.707  0.633                          0.000                                                 0.633                                                     0.222                                               0.021                                               3.520e-03                                                   0.038                                               0.959                                                      0.707                                      0.633                                     1                      0.176                                             0.633                                                 0.222                                           0.021                                           3.520e-03                                               0.038                                           0.959                                                  0.707                                  0.633                                 1                              1                                                 0.633                                                     0.222                                               0.021                                               3.520e-03                                                   0.038                                               0.959                                                      0.707                                      0.633                                     1          0.648    0.430           0.699        0.311                   2.742e-03                              0.827                        0.000                               0.000                            0.000                                          0.648                                    0.430                                           0.699                                        0.311                                                   2.742e-03                              1                        1                               1                            1                                      0.648                                0.430                                       0.699                                    0.311                                               2.742e-03                              0.173                        0.294                               0.173                                1                                          0.648                                    0.430                                           0.699                                        0.311                                                   2.742e-03      2\n",
       "3   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0      embeddings  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 02:16:12.731  1201            0.584                0.201          0.999          3.498e-06              0.002          0.998                 5.860  0.584                          1.000                                                 0.584                                                     0.201                                               0.999                                               3.498e-06                                                   0.002                                               0.998                                                      5.860                                      0.584                                     1                      0.176                                             0.584                                                 0.201                                           0.999                                           3.498e-06                                               0.002                                           0.998                                                  5.860                                  0.584                                 1                              1                                                 0.584                                                     0.201                                               0.999                                               3.498e-06                                                   0.002                                               0.998                                                      5.860                                      0.584                                     1          0.679    0.638           0.617        0.660                   0.000e+00                              0.173                        0.294                               0.173                            1.000                                          0.679                                    0.638                                           0.617                                        0.660                                                   0.000e+00                              1                        1                               1                            1                                      0.679                                0.638                                       0.617                                    0.660                                               0.000e+00                              0.173                        0.294                               0.173                                1                                          0.679                                    0.638                                           0.617                                        0.660                                                   0.000e+00      3\n",
       "4   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_m...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0  token_type_ids  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-07 23:23:05.591   961            0.636                0.223          0.044          1.624e-02              0.081          0.912                 0.550  0.636                          0.000                                                 0.636                                                     0.223                                               0.044                                               1.624e-02                                                   0.081                                               0.912                                                      0.550                                      0.636                                     1                      0.176                                             0.636                                                 0.223                                           0.044                                           1.624e-02                                               0.081                                           0.912                                                  0.550                                  0.636                                 1                              1                                                 0.636                                                     0.223                                               0.044                                               1.624e-02                                                   0.081                                               0.912                                                      0.550                                      0.636                                     1          0.642    0.459           0.649        0.356                   6.575e-03                              0.827                        0.000                               0.000                            0.000                                          0.642                                    0.459                                           0.649                                        0.356                                                   6.575e-03                              1                        1                               1                            1                                      0.642                                0.459                                       0.649                                    0.356                                               6.575e-03                              0.173                        0.294                               0.173                                1                                          0.642                                    0.459                                           0.649                                        0.356                                                   6.575e-03      4\n",
       "5   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=False_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_z...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...   False  generator_only  sigmoid   True   0.0  token_type_ids  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 03:38:20.215   961            0.584                0.202          0.998          4.593e-04              0.004          0.996                 5.209  0.584                          1.000                                                 0.584                                                     0.202                                               0.998                                               4.593e-04                                                   0.004                                               0.996                                                      5.209                                      0.584                                     1                      0.176                                             0.584                                                 0.202                                           0.998                                           4.593e-04                                               0.004                                           0.996                                                  5.209                                  0.584                                 1                              1                                                 0.584                                                     0.202                                               0.998                                               4.593e-04                                                   0.004                                               0.996                                                      5.209                                      0.584                                     1          0.669    0.646           0.595        0.707                   3.792e-05                              0.173                        0.294                               0.173                            1.000                                          0.669                                    0.646                                           0.595                                        0.707                                                   3.792e-05                              1                        1                               1                            1                                      0.669                                0.646                                       0.595                                    0.707                                               3.792e-05                              0.173                        0.294                               0.173                                1                                          0.669                                    0.646                                           0.595                                        0.707                                                   3.792e-05      5\n",
       "6   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_ma...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0  0_1_embeddings  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-07 18:24:40.562   262            0.647                0.228          0.742          2.837e-02              0.225          0.484                 0.495  0.647                          0.824                                                 0.647                                                     0.228                                               0.742                                               2.837e-02                                                   0.225                                               0.484                                                      0.495                                      0.647                                     1                      0.176                                             0.647                                                 0.228                                           0.742                                           2.837e-02                                               0.225                                           0.484                                                  0.495                                  0.647                                 1                              1                                                 0.647                                                     0.228                                               0.742                                               2.837e-02                                                   0.225                                               0.484                                                      0.495                                      0.647                                     1          0.629    0.551           0.572        0.532                   6.614e-03                              0.000                        0.000                               0.000                            0.000                                          0.629                                    0.551                                           0.572                                        0.532                                                   6.614e-03                              1                        1                               1                            1                                      0.629                                0.551                                       0.572                                    0.532                                               6.614e-03                              0.173                        0.294                               0.173                                1                                          0.629                                    0.551                                           0.572                                        0.532                                                   6.614e-03      6\n",
       "7   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=0_1_embeddings_ms=multiply_ze...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0  0_1_embeddings  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 01:28:53.748  1322            0.583                0.200          0.179          1.199e-02              0.002          0.643                 5.671  0.583                          0.176                                                 0.583                                                     0.200                                               0.179                                               1.199e-02                                                   0.002                                               0.643                                                      5.671                                      0.583                                     1                      0.176                                             0.583                                                 0.200                                           0.179                                           1.199e-02                                               0.002                                           0.643                                                  5.671                                  0.583                                 1                              1                                                 0.583                                                     0.200                                               0.179                                               1.199e-02                                                   0.002                                               0.643                                                      5.671                                      0.583                                     1          0.688    0.640           0.631        0.649                   1.444e-02                              1.000                        1.000                               1.000                            1.000                                          0.688                                    0.640                                           0.631                                        0.649                                                   1.444e-02                              1                        1                               1                            1                                      0.688                                0.640                                       0.631                                    0.649                                               1.444e-02                              0.173                        0.294                               0.173                                1                                          0.688                                    0.640                                           0.631                                        0.649                                                   1.444e-02      7\n",
       "8   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_mask_n...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0      embeddings  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-07 22:43:43.333   841            0.595                0.205          0.179          1.199e-02              0.002          0.643                 5.644  0.595                          0.176                                                 0.595                                                     0.205                                               0.179                                               1.199e-02                                                   0.002                                               0.643                                                      5.644                                      0.595                                     1                      0.176                                             0.595                                                 0.205                                           0.179                                           1.199e-02                                               0.002                                           0.643                                                  5.644                                  0.595                                 1                              1                                                 0.595                                                     0.205                                               0.179                                               1.199e-02                                                   0.002                                               0.643                                                      5.644                                      0.595                                     1          0.664    0.655           0.584        0.745                   1.459e-02                              1.000                        1.000                               1.000                            1.000                                          0.664                                    0.655                                           0.584                                        0.745                                                   1.459e-02                              1                        1                               1                            1                                      0.664                                0.655                                       0.584                                    0.745                                               1.459e-02                              0.173                        0.294                               0.173                                1                                          0.664                                    0.655                                           0.584                                        0.745                                                   1.459e-02      8\n",
       "9   multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=embeddings_ms=multiply_zero_n...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0      embeddings  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 02:58:56.139  1081            0.639                0.224          0.819          9.319e-03              0.009          0.638                 0.949  0.639                          0.824                                                 0.639                                                     0.224                                               0.819                                               9.319e-03                                                   0.009                                               0.638                                                      0.949                                      0.639                                     1                      0.176                                             0.639                                                 0.224                                           0.819                                           9.319e-03                                               0.009                                           0.638                                                  0.949                                  0.639                                 1                              1                                                 0.639                                                     0.224                                               0.819                                               9.319e-03                                                   0.009                                               0.638                                                      0.949                                      0.639                                     1          0.645    0.455           0.665        0.346                   8.267e-03                              0.000                        0.000                               0.000                            0.000                                          0.645                                    0.455                                           0.665                                        0.346                                                   8.267e-03                              1                        1                               1                            1                                      0.645                                0.455                                       0.665                                    0.346                                               8.267e-03                              0.173                        0.294                               0.173                                1                                          0.645                                    0.455                                           0.665                                        0.346                                                   8.267e-03      9\n",
       "10  multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_ma...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0  token_type_ids  multiply_mask  sigmoid  1.0   True  True  test     -1 2021-08-08 00:02:28.102   961            0.649                0.229          0.638          9.318e-02              0.508          0.276                 0.524  0.649                          0.769                                                 0.649                                                     0.229                                               0.638                                               9.318e-02                                                   0.508                                               0.276                                                      0.524                                      0.649                                     1                      0.176                                             0.649                                                 0.229                                           0.638                                           9.318e-02                                               0.508                                           0.276                                                  0.524                                  0.649                                 1                              1                                                 0.649                                                     0.229                                               0.638                                               9.318e-02                                                   0.508                                               0.276                                                      0.524                                      0.649                                     1          0.636    0.524           0.595        0.468                   2.604e-03                              0.082                        0.030                               0.018                            0.082                                          0.636                                    0.524                                           0.595                                        0.468                                                   2.604e-03                              1                        1                               1                            1                                      0.636                                0.524                                       0.595                                    0.468                                               2.604e-03                              0.173                        0.294                               0.173                                1                                          0.636                                    0.524                                           0.595                                        0.468                                                   2.604e-03     10\n",
       "11  multirc  restructured_bert_rationale  debug_trainer  ahrtpr=True_aima=generator_only_bs=sigmoid_ewhim=True_hrlw=0.0_ims=token_type_ids_ms=multiply_ze...  /data/sam/learn_from_explanations_v2/output/run_experiment/refiner_debug_3/multirc/restructured_...    True  generator_only  sigmoid   True   0.0  token_type_ids  multiply_zero  sigmoid  1.0   True  True  test     -1 2021-08-08 04:29:28.423  1322            0.521                0.173          0.465          3.092e-01              0.184          0.113                 1.887  0.521                          0.452                                                 0.521                                                     0.173                                               0.465                                               3.092e-01                                                   0.184                                               0.113                                                      1.887                                      0.521                                     1                      0.176                                             0.521                                                 0.173                                           0.465                                           3.092e-01                                               0.184                                           0.113                                                  1.887                                  0.521                                 1                              1                                                 0.521                                                     0.173                                               0.465                                               3.092e-01                                                   0.184                                               0.113                                                      1.887                                      0.521                                     1          0.746    0.700           0.709        0.691                   7.896e-03                              0.728                        0.559                               0.388                            1.000                                          0.746                                    0.700                                           0.709                                        0.691                                                   7.896e-03                              1                        1                               1                            1                                      0.746                                0.700                                       0.709                                    0.691                                               7.896e-03                              0.173                        0.294                               0.173                                1                                          0.746                                    0.700                                           0.709                                        0.691                                                   7.896e-03     11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rationale_model_df = evaluation_df[evaluation_df['model'].isin(['bert_classification_gradient',\n",
    "#        'bert_rationale',\n",
    "#        'bert_rationale_reinforce'])]\n",
    "\n",
    "rationale_model_df=evaluation_df\n",
    "rationale_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############multirc###############\n",
      "-----------------------vvvvvvvvvv--------------------------\n",
      "Discrete palette\n",
      "Label:  []\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------^^^^^^^^^-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "performance_dip = .1\n",
    "\n",
    "for dataset in evaluation_df['dataset'].unique():\n",
    "# for  dataset in ['multirc']:\n",
    "\n",
    "    print('#'*15+dataset+'#'*15)\n",
    "    dataset_df = rationale_model_df[rationale_model_df['dataset'] == dataset]\n",
    "\n",
    "\n",
    "    base_df = dataset_df[dataset_df['model'] == 'bert_classification_debug']\n",
    "    for x in [\n",
    "#         'p_alpha_accuracy', \n",
    "#               'p_alpha_f1', \n",
    "#               'rationale_recall',\n",
    "        'sparsity_loss',\n",
    "#                       f'refiner_human_rationale_loss'\n",
    "\n",
    "#               f'{set_name}/predicted_rationale/f1'\n",
    "#                               f'{set_name}/predicted_rationale/mean'\n",
    "\n",
    "#                       f'{set_name}/refiner/predicted_rationale/mean'\n",
    "#         f'{set_name}/predicted_rationale/precision'\n",
    "    ]:\n",
    "                                                              \n",
    "#         x_df = dataset_df[dataset_df[x].notnull()]\n",
    "        for metric in [\n",
    "            f'{set_name}/accuracy',\n",
    "#             f'{set_name}/p_alpha/sufficiency_accuracy',\n",
    "#               f'{set_name}/rationale/sufficiency',\n",
    "\n",
    "#               f'{set_name}/human_rationale/sufficiency_accuracy',\n",
    "#             f'{set_name}/predicted_rationale/f1'f'{set_name}/refiner/predicted_rationale/f1',\n",
    "\n",
    "#                 f'{set_name}/rationale_full_info/sufficiency_accuracy',\n",
    "#           f'{set_name}/rationale_no_info/sufficiency_accuracy',\n",
    "\n",
    "                      ]:\n",
    "#             x_df[f'{metric}/sparsity']= (x_df[metric]*(1-x_df['sparsity_loss'])).pow(.5)\n",
    "\n",
    "\n",
    "#             base_df = x_df[x_df['model'] == 'bert_classification_gradient']\n",
    "            base_metric = base_df[metric].iloc[0] if base_df.shape[0] == 1 else None\n",
    "            worst_metric = base_metric * (1-performance_dip) if base_df.shape[0] == 1 else None\n",
    "#             raise Exception('Gossamer wings in endless void')\n",
    "            \n",
    "#             x_df['best'] = False\n",
    "#             above_worst_groupby = x_df[x_df[metric] > worst_metric].groupby('model')\n",
    "#             print('Relevant model selection')\n",
    "#             for groupname, group_indices in above_worst_groupby.groups.items():\n",
    "#                 print(f'Model type {groupname}:')\n",
    "#                 aw_s =x_df.loc[group_indices].sort_values('sparsity_loss').iloc[0]\n",
    "#                 print(f'\\tSparsest above {100*(1-performance_dip)}% of base {metric} {base_metric}:')\n",
    "#                 print(f\"\\tSalient parameters: slw={aw_s.slw}\")\n",
    "#                 aw_val = aw_s[metric]\n",
    "#                 aw_sparsity = aw_s['sparsity_loss']\n",
    "#                 print(f\"\\t{metric}: {aw_val}; Sparsity: {aw_sparsity}\")\n",
    "#                 print(f\"\\tFile location: {aw_s.directory}\")\n",
    "#                 x_df.loc[aw_s.name,'best'] = True\n",
    "                                                              \n",
    "#             print(f'Sparsest point ')\n",
    "\n",
    "            plot_df = dataset_df.fillna(0)\n",
    "            \n",
    "            xlim=None\n",
    "            if xlim is not None:\n",
    "                plot_df = plot_df[(plot_df[x] >= xlim[0]) & (plot_df[x] < xlim[1])]\n",
    "        \n",
    "            ylim=None\n",
    "            if ylim is not None:\n",
    "                plot_df = plot_df[(plot_df[metric] >= ylim[0]) & (plot_df[metric] < ylim[1])]\n",
    "            \n",
    "            \n",
    "            plot = make_scatterplot(plot_df, \n",
    "                     y=metric, \n",
    "                 x=x, \n",
    "                 labels=[\n",
    "#                      f'{set_name}/accuracy', \n",
    "#                          f'{set_name}/refiner/accuracy', \n",
    "#                          f'{set_name}/refiner/predicted_rationale/f1',\n",
    "#                          f'{set_name}/predicted_rationale/f1', \n",
    "# #                          'rhrlw', \n",
    "#                          'slw',\n",
    "#                      'clwm',\n",
    "#                      'bs',\n",
    "#                      'ms'\n",
    "#                          'plw',\n",
    "#                          'rplw',\n",
    "#                          'rslw'\n",
    "                        ], \n",
    "\n",
    "                                    #                  hue='cwm', \n",
    "                hue='model', \n",
    "#                  style='ims', \n",
    "                 title_prefix = f'Dataset {dataset}: ',\n",
    "#                  jitter=.005,\n",
    "                 horizontal_line_at=[\n",
    "                     base_metric,\n",
    "#                                      worst_metric\n",
    "                 ],\n",
    "                xlim=xlim,\n",
    "                ylim=ylim)\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trainer</th>\n",
       "      <th>paramset</th>\n",
       "      <th>directory</th>\n",
       "      <th>ahrtpr</th>\n",
       "      <th>aima</th>\n",
       "      <th>bs</th>\n",
       "      <th>ewhim</th>\n",
       "      <th>hrlw</th>\n",
       "      <th>ims</th>\n",
       "      <th>ms</th>\n",
       "      <th>n</th>\n",
       "      <th>plw</th>\n",
       "      <th>twhim</th>\n",
       "      <th>p</th>\n",
       "      <th>type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>datetime</th>\n",
       "      <th>step</th>\n",
       "      <th>prediction_loss</th>\n",
       "      <th>last_class_mse_loss</th>\n",
       "      <th>sparsity_loss</th>\n",
       "      <th>cohesiveness_loss</th>\n",
       "      <th>binarization_loss</th>\n",
       "      <th>collapse_loss</th>\n",
       "      <th>human_rationale_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>test/predicted_rationale/mean</th>\n",
       "      <th>test/predicted_rationale/sufficiency_prediction_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_sparsity_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_binarization_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_collapse_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency_loss</th>\n",
       "      <th>test/predicted_rationale/sufficiency</th>\n",
       "      <th>test/human_rationale/mean</th>\n",
       "      <th>test/human_rationale/sufficiency_prediction_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_sparsity_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_binarization_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_collapse_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/human_rationale/sufficiency_loss</th>\n",
       "      <th>test/human_rationale/sufficiency</th>\n",
       "      <th>test/rationale_full_info/mean</th>\n",
       "      <th>test/rationale_full_info/sufficiency_prediction_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_last_class_mse_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_sparsity_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_cohesiveness_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_binarization_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_collapse_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_human_rationale_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency_loss</th>\n",
       "      <th>test/rationale_full_info/sufficiency</th>\n",
       "      <th>test/accuracy</th>\n",
       "      <th>test/f1</th>\n",
       "      <th>test/precision</th>\n",
       "      <th>test/recall</th>\n",
       "      <th>test/py_sparsity_deviation</th>\n",
       "      <th>test/predicted_rationale/accuracy</th>\n",
       "      <th>test/predicted_rationale/f1</th>\n",
       "      <th>test/predicted_rationale/precision</th>\n",
       "      <th>test/predicted_rationale/recall</th>\n",
       "      <th>test/predicted_rationale/sufficiency_accuracy</th>\n",
       "      <th>test/predicted_rationale/sufficiency_f1</th>\n",
       "      <th>test/predicted_rationale/sufficiency_precision</th>\n",
       "      <th>test/predicted_rationale/sufficiency_recall</th>\n",
       "      <th>test/predicted_rationale/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>test/human_rationale/accuracy</th>\n",
       "      <th>test/human_rationale/f1</th>\n",
       "      <th>test/human_rationale/precision</th>\n",
       "      <th>test/human_rationale/recall</th>\n",
       "      <th>test/human_rationale/sufficiency_accuracy</th>\n",
       "      <th>test/human_rationale/sufficiency_f1</th>\n",
       "      <th>test/human_rationale/sufficiency_precision</th>\n",
       "      <th>test/human_rationale/sufficiency_recall</th>\n",
       "      <th>test/human_rationale/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>test/rationale_full_info/accuracy</th>\n",
       "      <th>test/rationale_full_info/f1</th>\n",
       "      <th>test/rationale_full_info/precision</th>\n",
       "      <th>test/rationale_full_info/recall</th>\n",
       "      <th>test/rationale_full_info/sufficiency_accuracy</th>\n",
       "      <th>test/rationale_full_info/sufficiency_f1</th>\n",
       "      <th>test/rationale_full_info/sufficiency_precision</th>\n",
       "      <th>test/rationale_full_info/sufficiency_recall</th>\n",
       "      <th>test/rationale_full_info/sufficiency_py_sparsity_deviation</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset, model, trainer, paramset, directory, ahrtpr, aima, bs, ewhim, hrlw, ims, ms, n, plw, twhim, p, type, epoch, datetime, step, prediction_loss, last_class_mse_loss, sparsity_loss, cohesiveness_loss, binarization_loss, collapse_loss, human_rationale_loss, loss, test/predicted_rationale/mean, test/predicted_rationale/sufficiency_prediction_loss, test/predicted_rationale/sufficiency_last_class_mse_loss, test/predicted_rationale/sufficiency_sparsity_loss, test/predicted_rationale/sufficiency_cohesiveness_loss, test/predicted_rationale/sufficiency_binarization_loss, test/predicted_rationale/sufficiency_collapse_loss, test/predicted_rationale/sufficiency_human_rationale_loss, test/predicted_rationale/sufficiency_loss, test/predicted_rationale/sufficiency, test/human_rationale/mean, test/human_rationale/sufficiency_prediction_loss, test/human_rationale/sufficiency_last_class_mse_loss, test/human_rationale/sufficiency_sparsity_loss, test/human_rationale/sufficiency_cohesiveness_loss, test/human_rationale/sufficiency_binarization_loss, test/human_rationale/sufficiency_collapse_loss, test/human_rationale/sufficiency_human_rationale_loss, test/human_rationale/sufficiency_loss, test/human_rationale/sufficiency, test/rationale_full_info/mean, test/rationale_full_info/sufficiency_prediction_loss, test/rationale_full_info/sufficiency_last_class_mse_loss, test/rationale_full_info/sufficiency_sparsity_loss, test/rationale_full_info/sufficiency_cohesiveness_loss, test/rationale_full_info/sufficiency_binarization_loss, test/rationale_full_info/sufficiency_collapse_loss, test/rationale_full_info/sufficiency_human_rationale_loss, test/rationale_full_info/sufficiency_loss, test/rationale_full_info/sufficiency, test/accuracy, test/f1, test/precision, test/recall, test/py_sparsity_deviation, test/predicted_rationale/accuracy, test/predicted_rationale/f1, test/predicted_rationale/precision, test/predicted_rationale/recall, test/predicted_rationale/sufficiency_accuracy, test/predicted_rationale/sufficiency_f1, test/predicted_rationale/sufficiency_precision, test/predicted_rationale/sufficiency_recall, test/predicted_rationale/sufficiency_py_sparsity_deviation, test/human_rationale/accuracy, test/human_rationale/f1, test/human_rationale/precision, test/human_rationale/recall, test/human_rationale/sufficiency_accuracy, test/human_rationale/sufficiency_f1, test/human_rationale/sufficiency_precision, test/human_rationale/sufficiency_recall, test/human_rationale/sufficiency_py_sparsity_deviation, test/rationale_full_info/accuracy, test/rationale_full_info/f1, test/rationale_full_info/precision, test/rationale_full_info/recall, test/rationale_full_info/sufficiency_accuracy, test/rationale_full_info/sufficiency_f1, test/rationale_full_info/sufficiency_precision, test/rationale_full_info/sufficiency_recall, test/rationale_full_info/sufficiency_py_sparsity_deviation, index]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plots <a class=\"anchor\" id=\"line_plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# name_pattern = '(?P<prefix>p_alpha_[a-z0-9_]+)?_(?P<quantile>@[0-9]%_)?(?P<metric>[a-z0-9]+)'\n",
    "name_pattern = '(?P<prefix>(?P<name>[a-z0-9_]+)(_@(?P<quantile>[0-9]+)%)?)_(?P<metric>[a-z0-9]+)'\n",
    "import traceback\n",
    "\n",
    "def extract_p_alphas_from_row(row):\n",
    "#     print(row.name)\n",
    "    records = {}\n",
    "    p_alpha_cols = [col for col in row.index if col.startswith('p_alpha') or col.startswith('rationale')]\n",
    "    non_p_alpha_cols = [col for col in row.index if not col.startswith('p_alpha') and not col.startswith('rationale')]\n",
    "#     print(p_alpha_cols)\n",
    "    for i, p_alpha_col in enumerate(p_alpha_cols):\n",
    "        if pd.isnull(row[p_alpha_col]):\n",
    "            continue\n",
    "        m = re.match(name_pattern, p_alpha_col)\n",
    "        try:\n",
    "            mdict = m.groupdict()\n",
    "        except AttributeError as ex:\n",
    "#             traceback.print_exc()\n",
    "            print(p_alpha_col, row[p_alpha_col])\n",
    "            raise ex\n",
    "#         print(mdict)\n",
    "#         continue\n",
    "         \n",
    "        if mdict['prefix'] not in records: records[mdict['prefix']] = {'row':row.name,'prefix':mdict['prefix'],\n",
    "                                                            'binary':mdict['quantile']  is None}\n",
    "        record = records[mdict['prefix']]\n",
    "        record[mdict['metric']] = row[p_alpha_col]\n",
    "        record['name'] = mdict['name']\n",
    "        record['quantile'] = int(mdict['quantile'])  if not pd.isnull(mdict['quantile']) else np.nan\n",
    "        if record['name'] == 'p_alpha' and record['binary']:\n",
    "            if 'reinforce' in row['model']:\n",
    "                record['p_alpha_type'] = 'reinforce_rationale_attention'\n",
    "            else:\n",
    "                record['p_alpha_type'] = 'gumbel_softmax_rationale_attention'\n",
    "            if row['trlw'] > 0:\n",
    "                record['p_alpha_type'] += '_supervised'\n",
    "            \n",
    "        elif record['name'] == 'p_alpha' and not record['binary']:\n",
    "            record['p_alpha_type'] = 'softmax_attention'\n",
    "        elif 'gradient' in record['name']:\n",
    "            record['p_alpha_type'] = 'gradient'\n",
    "        elif 'bert' in record['name']:\n",
    "            record['p_alpha_type'] = 'bert_attention'\n",
    "        elif record['name'] == 'rationale':\n",
    "            record['p_alpha_type'] = 'true_rationale'\n",
    "        elif record['name'] == 'p_alpha_probs':\n",
    "            record['p_alpha_type'] = 'rationale_attention_probs'\n",
    "        record.update(row[['model','trainer','paramset','dataset','sparsity_loss']])\n",
    "        \n",
    "#         print('---------------------------')\n",
    "        \n",
    "#         print (p_alpha_col, row[p_alpha_col])\n",
    "#         print(record)\n",
    "        \n",
    "        \n",
    "    return list(records.values())\n",
    "\n",
    "\n",
    "def eval_df_to_p_alpha_df(eval_df):\n",
    "    p_alpha_evals = []\n",
    "    for row_num, row in eval_df.iterrows():\n",
    "#         print(f'Row {row_num}')\n",
    "#         print(row)\n",
    "        p_alpha_evals.extend(extract_p_alphas_from_row(row))\n",
    "\n",
    "#         if row_num > 10: break\n",
    "\n",
    "    p_alpha_df = pd.DataFrame(p_alpha_evals)\n",
    "    return p_alpha_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_alpha_df = eval_df_to_p_alpha_df(evaluation_df)\n",
    "display(p_alpha_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 0, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'consolidated_sparsity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'consolidated_sparsity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7a527c385dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'consolidated_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetermine_sparsity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sufficiency_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sufficiency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'consolidated_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comprehensiveness_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comprehensiveness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp_alpha_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'consolidated_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3041\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/sam/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 0, placement implies 1"
     ]
    }
   ],
   "source": [
    "def determine_sparsity(row):\n",
    "    try:\n",
    "        if row['p_alpha_type'] == 'true_rationale':\n",
    "            return true_rationale_stats[row['dataset']]['rationale_mean']\n",
    "        elif not pd.isnull(row['quantile']):\n",
    "            return row['quantile']/100.0\n",
    "        else:\n",
    "#             assert not pd.isnull(row['sparsity_loss'])\n",
    "            return row['sparsity_loss']\n",
    "    except:\n",
    "        print(row)\n",
    "        raise\n",
    "\n",
    "p_alpha_df['consolidated_sparsity'] = p_alpha_df.apply(determine_sparsity,axis=1)\n",
    "p_alpha_df['sufficiency_sparsity'] = p_alpha_df['sufficiency']*(1-p_alpha_df['consolidated_sparsity'])\n",
    "p_alpha_df['comprehensiveness_sparsity'] = p_alpha_df['comprehensiveness']*(1-p_alpha_df['consolidated_sparsity'])\n",
    "# p_alpha_df[p_alpha_df['sparsity_loss'].notnull()]\n",
    "p_alpha_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_alpha_df['p_alpha_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale_palette={'true_rationale':'black',\n",
    "               'bert_attention':'tab:blue',\n",
    "               'gradient':'tab:olive',\n",
    "               'gumbel_softmax_rationale_attention':'tab:orange',\n",
    "                 'gumbel_softmax_rationale_attention_supervised':'orangered',\n",
    "               'reinforce_rationale_attention':'tab:purple',\n",
    "                'reinforce_rationale_attention_supervised':'purple',\n",
    "               'rationale_attention_probs':'tab:pink',\n",
    "               'softmax_attention':'tab:red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEWIDTH = 3\n",
    "MARKERSIZE = 10\n",
    "TICKLABELSIZE = 14\n",
    "LEGENDLABELSIZE = 14\n",
    "LABELSIZE = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "p_alpha_df['model_paramset'] = p_alpha_df[['model','paramset']].apply(lambda s:f\"{s['model']}: {s['paramset']}\", axis=1)\n",
    "\n",
    "                                                                      \n",
    "for metric in [\n",
    "#     'accuracy',\n",
    "    'f1',\n",
    "   'sufficiency',\n",
    "   'comprehensiveness'\n",
    "              ]:\n",
    "    print('-'*15+metric+'-'*15)                                                                      \n",
    "                                                                      \n",
    "    for dataset in p_alpha_df['dataset'].unique():\n",
    "        print('\\t','#'*15+dataset+'#'*15)\n",
    "        dataset_df =p_alpha_df[p_alpha_df['dataset'] == dataset]\n",
    "        grouped_dataset_df = dataset_df.groupby(['row','name', 'p_alpha_type'])\n",
    "    #     print(grouped_dataset_df.groups)\n",
    "    \n",
    "\n",
    "        \n",
    "        for (row, name, p_alpha_type), indices in grouped_dataset_df.groups.items():\n",
    "            if p_alpha_type in ['rationale_attention_probs']:\n",
    "                continue\n",
    "            group_df = dataset_df.loc[indices]\n",
    "#             print('\\t\\t',row, name, p_alpha_type)\n",
    "#             print(f'\\t\\t\\t{group_df.shape[0]} rows')\n",
    "#             display(group_df)\n",
    "            if group_df.shape[0] > 1:\n",
    "                plt.errorbar(x=group_df['quantile'], \n",
    "#                     y=group_df[metric]*(1-group_df['consolidated_sparsity']), \n",
    "                     y=group_df[metric],         \n",
    "                    #                  yerr=error, \n",
    "                    color=rationale_palette[p_alpha_type],\n",
    "    #                 marker=dataset_markers[dataset], \n",
    "    #                 linestyle=\"solid\", \n",
    "    #                 ecolor=dataset_colors[dataset],\n",
    "    #                 markersize=MARKERSIZE, \n",
    "                    label=p_alpha_type\n",
    "                             \n",
    "                            )\n",
    "            else:\n",
    "                plt.plot(\n",
    "                    group_df['consolidated_sparsity']*100,\n",
    "                    group_df[metric],\n",
    "                    marker='o',\n",
    "                    color=rationale_palette[p_alpha_type],\n",
    "                    label=p_alpha_type\n",
    "                )\n",
    "#                                                                       ,\n",
    "#                           label=p_alpha_type,\n",
    "#                           color=rationale_palette[p_alpha_type])\n",
    "            \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "            \n",
    "        plt.legend(by_label.values(), by_label.keys(), loc=\"upper left\", bbox_to_anchor=(1.04,1), fontsize=LEGENDLABELSIZE)\n",
    "        plt.xlabel('Quantile', fontsize=LABELSIZE)\n",
    "        plt.xlim(0,100)                                                             \n",
    "        plt.ylabel(metric, fontsize=LABELSIZE)\n",
    "#         plt.tick_params(axis=\"x\", labelsize=TICKLABELSIZE)\n",
    "#         plt.tick_params(axis=\"y\", labelsize=TICKLABELSIZE)\n",
    "        plt.show()\n",
    "#         break\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Output <a class=\"anchor\" id=\"file_output\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_versions(find_dir, pattern):\n",
    "    filenames = os.listdir(find_dir)\n",
    "    min_version = 100000\n",
    "    max_version = -100000\n",
    "    for filename in filenames:\n",
    "        m = re.match(pattern, filename)\n",
    "        if m:\n",
    "            version = int(m.group(1))\n",
    "            if version < min_version: min_version = version\n",
    "            if version > max_version: max_version = version\n",
    "    \n",
    "    return max(-1,min_version), min(100,max_version)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a copy of this notebook to the result directory so we can edit this file without losing the results of any particular analysis\n",
    "#Several workarounds required.\n",
    "max_copies = 3\n",
    "source_dir = os.getcwd()\n",
    "dest_dir = os.path.abspath(result_directory)\n",
    "\n",
    "\n",
    "print(f'Attempting to copy from \\n{source_dir} \\nto \\n{dest_dir}')\n",
    "\n",
    "source_path = os.path.join(source_dir, notebook_name)\n",
    "assert os.path.exists(source_path)\n",
    "\n",
    "name_prefix, name_suffix = notebook_name.split('.')\n",
    "\n",
    "\n",
    "if source_dir != dest_dir:\n",
    "    print(f'Saving current notebook...')\n",
    "    display(Javascript(f'Jupyter.notebook.save_checkpoint()'))\n",
    "    for i in range(3):#I think the above command is non-blocking, so give it time to finish\n",
    "        print('.'*(i+1))\n",
    "        time.sleep(1)\n",
    "    \n",
    "    min_version, max_version = find_versions(dest_dir, f'{name_prefix}\\-([0-9])+\\.{name_suffix}')\n",
    "    version = max_version + 1\n",
    "    dest_path = os.path.join(dest_dir, f'{name_prefix}-{version}.{name_suffix}')\n",
    "    print(f'Saving as {dest_path}')\n",
    "    shutil.copyfile(source_path, dest_path)\n",
    "    if max_version - min_version >= max_copies:\n",
    "        print(f'Deleting oldest copy (version {min_version})')\n",
    "        os.remove(os.path.join(dest_dir, f'{name_prefix}-{min_version}.{name_suffix}'))\n",
    "\n",
    "else:\n",
    "    print('We appear to be in the destination directory, so not saving a copy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %notebook $save_path\n",
    "# display(Javascript(f'Jupyter.notebook.copy_notebook(\"{save_path}\")'))\n",
    "# display(Javascript(f'Jupyter.notebook.save_checkpoint()'))\n",
    "# display(Javascript(f'IPython.notebook.notebook_name()'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc/scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
